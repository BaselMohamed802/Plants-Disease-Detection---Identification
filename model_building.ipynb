{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02427fa5",
   "metadata": {},
   "source": [
    "# introduction\n",
    "This file is used to train an image segmentation model to detect plant diseases in order to be used in an application to detect plant health in real-time and classify what type of disease is it inflicted with if any.\n",
    "\n",
    "## Dataset used\n",
    "The dataset used is the PlantVillage Dataset from Kaggle. The dataset can be found [here](https://www.kaggle.com/datasets/alexisbcook/plantvillage)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886594f7",
   "metadata": {},
   "source": [
    "# 1. Dataset\n",
    "In this section, we will create:\n",
    "1. the Dataset class.\n",
    "2. the DataLoader class.\n",
    "\n",
    "And we will explore the dataset and visualize each class size in training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6c53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933ebc7",
   "metadata": {},
   "source": [
    "## 1.1. Creating a transformation pipeline\n",
    "The pipeline consists of the following transformations:\n",
    "1. Resize.\n",
    "2. RandomCrop.\n",
    "3. Rotate limit of 40 degrees.\n",
    "4. HorizontalFlip.\n",
    "5. VerticalFlip.\n",
    "6. RGBShift.\n",
    "7. OneOf: Blur or ColorJitter.\n",
    "8. Normalize the images.\n",
    "9. Converting to tensor via ToTensorV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a transformation pipeline using Albumentations\n",
    "transform = A.Compose([\n",
    "        A.RandomRotate90(),\n",
    "        A.HorizontalFlip(),\n",
    "        A.Transpose(),\n",
    "        A.GaussNoise(),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.3),\n",
    "            A.GridDistortion(p=.1),\n",
    "        ], p=0.2),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(clip_limit=2),\n",
    "            A.RandomBrightnessContrast(),\n",
    "        ], p=0.3),\n",
    "        A.HueSaturationValue(p=0.3),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "], additional_targets={'mask': 'mask'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526a9b7",
   "metadata": {},
   "source": [
    "## 1.2. Dataset Class & DataLoaders for the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e611bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208361e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the custom Dataset class\n",
    "class PlantVillageSegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = sorted(list(Path(image_dir).rglob(\"*.jpg\")))\n",
    "        self.mask_paths = []\n",
    "        for img_path in self.image_paths:\n",
    "            # build corresponding mask path\n",
    "            rel_path = img_path.relative_to(image_dir)\n",
    "            mask_path = Path(mask_dir) / rel_path.parent / f\"{img_path.stem}_final_masked.jpg\"\n",
    "            if mask_path.exists():\n",
    "                self.mask_paths.append(mask_path)\n",
    "            else:\n",
    "                # Skip if mask missing\n",
    "                self.image_paths.remove(img_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(self.mask_paths[idx]).convert(\"L\"))\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "\n",
    "        mask = (mask > 0).float()\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320345cc",
   "metadata": {},
   "source": [
    "- Adding the dataset file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df79658",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loc = \"D:\\Work Projects\\AI & ML Projects\\Plants-Disease-Detection---Identification\\data\"\n",
    "color_full_images_dir = \"D:\\Work Projects\\AI & ML Projects\\Plants-Disease-Detection---Identification\\data\\color\"\n",
    "segmented_images_dir = \"D:\\Work Projects\\AI & ML Projects\\Plants-Disease-Detection---Identification\\data\\segmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5c3853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Size: 42473\n",
      "Validation Dataset Size: 5296\n",
      "Test Dataset Size: 5338\n"
     ]
    }
   ],
   "source": [
    "# Add class instances of Train, Validation, Test split datasets\n",
    "train_dataset = PlantVillageSegmentationDataset(\n",
    "    image_dir=os.path.join(color_full_images_dir, 'train'),\n",
    "    mask_dir=os.path.join(segmented_images_dir, 'train'),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = PlantVillageSegmentationDataset(\n",
    "    image_dir=os.path.join(color_full_images_dir, 'valid'),\n",
    "    mask_dir=os.path.join(segmented_images_dir, 'valid'),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = PlantVillageSegmentationDataset(\n",
    "    image_dir=os.path.join(color_full_images_dir, 'test'),\n",
    "    mask_dir=os.path.join(segmented_images_dir, 'test'),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Testing for image size\n",
    "print(f\"Train Dataset Size: {len(train_dataset)}\")\n",
    "print(f\"Validation Dataset Size: {len(val_dataset)}\")\n",
    "print(f\"Test Dataset Size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "457efef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e2ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing DataLoaders\n",
    "for images, masks in test_loader:\n",
    "    print(f\"Image batch shape: {images.shape}\")\n",
    "    print(f\"Mask batch shape: {masks.shape}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
